<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>HERAKLES: Hierarchical Skill Compilation for LLM Agents - Loris Gaven</title>
    <meta name="description" content="HERAKLES: A framework for hierarchical autotelic LLM agents that continuously compile mastered goals into reusable skills for open-ended learning.">
    <meta name="keywords" content="HERAKLES, LLM Agents, Hierarchical Reinforcement Learning, Skill Compilation, Open-ended Learning, Loris Gaven">
    <meta name="author" content="Loris Gaven">
    <meta name="robots" content="index, follow">
    <link rel="canonical" href="https://lgaven.me/publications/herakles.html">

    <meta property="og:type" content="article">
    <meta property="og:url" content="https://lgaven.me/publications/herakles.html">
    <meta property="og:title" content="HERAKLES: Hierarchical Skill Compilation for LLM Agents">
    <meta property="og:description" content="Hierarchical Skill Compilation for Open-ended LLM Agents.">
    <meta property="og:image" content="https://lgaven.me/images/icon.png">

    <meta name="twitter:card" content="summary">
    <meta name="twitter:creator" content="@lorisgaven">
    <meta name="twitter:title" content="HERAKLES: Hierarchical Skill Compilation for LLM Agents">
    <meta name="twitter:description" content="Hierarchical Skill Compilation for Open-ended LLM Agents.">

    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "ScholarlyArticle",
        "headline": "HERAKLES: Hierarchical Skill Compilation for Open-ended LLM Agents",
        "author": [
            {"@type": "Person", "name": "Thomas Carta"},
            {"@type": "Person", "name": "Cl√©ment Romac"},
            {"@type": "Person", "name": "Loris Gaven"},
            {"@type": "Person", "name": "Pierre-Yves Oudeyer"},
            {"@type": "Person", "name": "Olivier Sigaud"},
            {"@type": "Person", "name": "Sylvain Lamprier"}
        ],
        "datePublished": "2025",
        "url": "https://lgaven.me/publications/herakles.html"
    }
    </script>

    <link rel="icon" href="../images/icon.png" type="image/png">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <nav>
        <a href="../index.html">&larr; Back to home</a>
    </nav>

    <article class="publication-page">
        <h1>HERAKLES: Hierarchical Skill Compilation for Open-ended LLM Agents</h1>
        <p class="authors">T. Carta, C. Romac, L. Gaven, P-Y. Oudeyer, O. Sigaud, S. Lamprier</p>
        <p class="venue">arXiv preprint, 2025</p>

        <div class="links">
            <a href="https://arxiv.org/abs/2508.14751" target="_blank">Paper</a>
            <a href="#" target="_blank">Code</a>
        </div>

        <section>
            <h2>Abstract</h2>
            <p>Open-ended AI agents need to be able to learn efficiently goals of increasing complexity, abstraction and heterogeneity over their lifetime. Beyond sampling efficiently their own goals, autotelic agents specifically need to be able to keep the growing complexity of goals under control, limiting the associated growth in sample and computational complexity. To adress this challenge, recent approaches have leveraged hierarchical reinforcement learning (HRL) and language, capitalizing on its compositional and combinatorial generalization capabilities to acquire temporally extended reusable behaviours. Existing approaches use expert defined spaces of subgoals over which they instantiate a hierarchy, and often assume pre-trained associated low-level policies. Such designs are inadequate in open-ended scenarios, where goal spaces naturally diversify across a broad spectrum of difficulties. We introduce HERAKLES, a framework that enables a two-level hierarchical autotelic agent to continuously compile mastered goals into the low-level policy, executed by a small, fast neural network, dynamically expanding the set of subgoals available to the high-level policy. We train a Large Language Model (LLM) to serve as the high-level controller, exploiting its strengths in goal decomposition and generalization to operate effectively over this evolving subgoal space. We evaluate HERAKLES in the open-ended Crafter environment and show that it scales effectively with goal complexity, improves sample efficiency through skill compilation, and enables the agent to adapt robustly to novel challenges over time.</p>
        </section>

        <section>
            <h2>Citation</h2>
            <pre class="citation">@article{carta2025herakles,
  title={HERAKLES: Hierarchical Skill Compilation for Open-ended LLM Agents},
  author={Carta, Thomas and Romac, Cl{\'e}ment and Gaven, Loris and Oudeyer, Pierre-Yves and Sigaud, Olivier and Lamprier, Sylvain},
  journal={arXiv preprint arXiv:2508.14751},
  year={2025}
}</pre>
        </section>
    </article>
</body>
</html>
